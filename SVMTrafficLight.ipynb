{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load of the file of data about the 50 last meters to the traffic light \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>55</th>\n",
       "      <th>50</th>\n",
       "      <th>45</th>\n",
       "      <th>40</th>\n",
       "      <th>35</th>\n",
       "      <th>30</th>\n",
       "      <th>25</th>\n",
       "      <th>20</th>\n",
       "      <th>15</th>\n",
       "      <th>10</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>37.25</td>\n",
       "      <td>37.11</td>\n",
       "      <td>36.89</td>\n",
       "      <td>36.70</td>\n",
       "      <td>36.56</td>\n",
       "      <td>36.37</td>\n",
       "      <td>36.16</td>\n",
       "      <td>35.96</td>\n",
       "      <td>35.84</td>\n",
       "      <td>35.60</td>\n",
       "      <td>35.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>37.04</td>\n",
       "      <td>36.93</td>\n",
       "      <td>36.72</td>\n",
       "      <td>36.51</td>\n",
       "      <td>36.31</td>\n",
       "      <td>36.18</td>\n",
       "      <td>35.98</td>\n",
       "      <td>35.75</td>\n",
       "      <td>35.56</td>\n",
       "      <td>35.43</td>\n",
       "      <td>35.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>37.15</td>\n",
       "      <td>36.93</td>\n",
       "      <td>36.79</td>\n",
       "      <td>36.58</td>\n",
       "      <td>36.36</td>\n",
       "      <td>36.19</td>\n",
       "      <td>36.05</td>\n",
       "      <td>35.82</td>\n",
       "      <td>35.62</td>\n",
       "      <td>35.41</td>\n",
       "      <td>35.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.44</td>\n",
       "      <td>35.42</td>\n",
       "      <td>35.44</td>\n",
       "      <td>35.44</td>\n",
       "      <td>35.42</td>\n",
       "      <td>35.43</td>\n",
       "      <td>35.43</td>\n",
       "      <td>35.43</td>\n",
       "      <td>35.43</td>\n",
       "      <td>35.37</td>\n",
       "      <td>35.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>34.28</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.26</td>\n",
       "      <td>34.26</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.26</td>\n",
       "      <td>34.26</td>\n",
       "      <td>34.27</td>\n",
       "      <td>34.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class     55     50     45     40     35     30     25     20     15  \\\n",
       "0      1  37.25  37.11  36.89  36.70  36.56  36.37  36.16  35.96  35.84   \n",
       "1      1  37.04  36.93  36.72  36.51  36.31  36.18  35.98  35.75  35.56   \n",
       "2      1  37.15  36.93  36.79  36.58  36.36  36.19  36.05  35.82  35.62   \n",
       "3      1  35.44  35.42  35.44  35.44  35.42  35.43  35.43  35.43  35.43   \n",
       "4      1  34.28  34.27  34.26  34.26  34.27  34.27  34.27  34.26  34.26   \n",
       "\n",
       "      10      5  \n",
       "0  35.60  35.37  \n",
       "1  35.43  35.24  \n",
       "2  35.41  35.20  \n",
       "3  35.37  35.19  \n",
       "4  34.27  34.27  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "badBehaviourData = pd.read_csv(\"C:/Users/Ivan/Desktop/LastSimulations/Trafficlight-simulations/results.txt\",delim_whitespace=True, names =[ \"class\", 55,  50, 45,  40,  35,  30,  25,  20,  15,  10,  5])  \n",
    "badBehaviourData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division of the data in x and y axis\n",
    "We need to separate the class column that shows when a vehicle have a red light running (1), known as bad behaviour, and a right stop at the traffic light, known as right behaviour (0)\n",
    "\n",
    "> bad behaviour **(1)**\n",
    "\n",
    "> good behaviour **(0)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = badBehaviourData.drop('class', axis=1)  \n",
    "y = badBehaviourData['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Division of the data in training, test and validation datasets\n",
    "To do this we divide first all the data into training and test, and later we divide again the training dataset into training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Phase\n",
    "Now we have separate the different datasets we can train our SVM using the training data. Scikit-Learn contains the svm library, which contains built-in classes for different SVM algorithms. This class takes one parameter, which is the kernel type. This is very important. In the case of a simple SVM we simply set this parameter as \"linear\" since simple SVMs can only classify linearly separable data.\n",
    "\n",
    "The fit method of SVC class is called to train the algorithm on the training data, which is passed as a parameter to the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='poly',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='poly')  \n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions \n",
    "Once our model has been trained with the data, we perform the predictions, to later, evaluate the right working of the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svclassifier.predict(x_test)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Evaluation \n",
    "We do the confusion matrix and the classification report.\n",
    "Confusion matrix, precision, recall, and F1 measures are the most commonly used metrics for classification tasks. Scikit-Learn metrics library contains the classification_report and confusion_matrix methods, which can be readily used to find out the values for these important metrics.\n",
    "\n",
    "### Confusion matrix\n",
    "The confusion matrix represents in each column, the number of predictions for each class and in each row it represents the number of elements of each class in the real life. \n",
    "\n",
    "### Clasification report\n",
    "\n",
    "##### Precision\n",
    "Precision is the ability of a classiifer not to label an instance positive that is actually negative. For each class it is defined as as the ratio of true positives to the sum of true and false positives. Said another way, “for all instances classified positive, what percent was correct?”\n",
    "##### Recall\n",
    "Recall is the ability of a classifier to find all positive instances. For each class it is defined as the ratio of true positives to the sum of true positives and false negatives. Said another way, “for all instances that were actually positive, what percent was classified correctly?”\n",
    "##### F1 score\n",
    "The F1 score is a weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. Generally speaking, F1 scores are lower than accuracy measures as they embed precision and recall into their computation. As a rule of thumb, the weighted average of F1 should be used to compare classifier models, not global accuracy.\n",
    "##### Support\n",
    "Support is the number of actual occurrences of the class in the specified dataset. Imbalanced support in the training data may indicate structural weaknesses in the reported scores of the classifier and could indicate the need for stratified sampling or rebalancing. Support doesn’t change between models but instead diagnoses the evaluation process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1751   36]\n",
      " [   0 3957]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "good behaviour       1.00      0.98      0.99      1787\n",
      " bad behaviour       0.99      1.00      1.00      3957\n",
      "\n",
      "   avg / total       0.99      0.99      0.99      5744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['good behaviour', 'bad behaviour']\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System training using linear algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='linear')  \n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1701   86]\n",
      " [  19 3938]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "good behaviour       0.99      0.95      0.97      1787\n",
      " bad behaviour       0.98      1.00      0.99      3957\n",
      "\n",
      "   avg / total       0.98      0.98      0.98      5744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(x_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System training using rbf algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svclassifier = SVC(kernel='rbf')  \n",
    "svclassifier.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1771   16]\n",
      " [   1 3956]]\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "good behaviour       1.00      0.99      1.00      1787\n",
      " bad behaviour       1.00      1.00      1.00      3957\n",
      "\n",
      "   avg / total       1.00      1.00      1.00      5744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = svclassifier.predict(x_test)  \n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
